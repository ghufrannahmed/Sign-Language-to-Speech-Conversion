# Sign-Language-to-Speech-Conversion
This project implements a real-time, offline system for converting American Sign Language (ASL) gestures into both speech and text using Edge AI and IoT. Built with a Raspberry Pi, Pi Camera, and Python-based tools like OpenCV, MediaPipe, and pyttsx3, the system recognizes static ASL alphabet gestures and provides instant audio-visual feedback via a user-friendly GUI. Designed for accessibility and low-resource environments, it eliminates the need for cloud services, making it ideal for supporting speech-impaired individuals in real-world communication.
